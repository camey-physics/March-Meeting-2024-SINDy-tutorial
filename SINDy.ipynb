{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "610f36ff-7e6b-45bd-b5d3-57c6c5f1a390",
   "metadata": {},
   "source": [
    "## Connect your drive to google colab session - only needs to be done once"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4Ndf3E-OGksP",
   "metadata": {
    "id": "4Ndf3E-OGksP"
   },
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n",
    "import os\n",
    "os.listdir('/content/drive/MyDrive/SINDy_tutorial')\n",
    "path = '/content/drive/MyDrive/SINDy_tutorial/'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c250fcd-ae4e-4377-bea0-91f2f1c8996f",
   "metadata": {},
   "source": [
    "## Import libraries - only needs to be done once"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2046e394-dde7-40b5-bafc-e6fd1f263b48",
   "metadata": {
    "id": "2046e394-dde7-40b5-bafc-e6fd1f263b48"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import h5py\n",
    "import matplotlib.pyplot as plt\n",
    "os.chdir(path)\n",
    "from SINDy_tools import calc_gradients, sequentially_thresholded_LSQ"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92e8027e-2593-4817-aaec-26749c7a1705",
   "metadata": {},
   "source": [
    "## Load data - only needs to be done once"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a7eba39-1dac-4c4c-90c1-c10f8eace916",
   "metadata": {
    "id": "6a7eba39-1dac-4c4c-90c1-c10f8eace916"
   },
   "outputs": [],
   "source": [
    "f = h5py.File(path+'active_nematic.h5', 'r')\n",
    "dx = f['dx'][()]\n",
    "dt = f['dt'][()]\n",
    "Qf = np.moveaxis(f['qtensor'][::4], 0, -1)\n",
    "Qf = np.array([[Qf[0],Qf[1]],[Qf[1],-Qf[0]]])\n",
    "uf = np.moveaxis(f['velocity'][::4], 0, -1)\n",
    "Pf = np.moveaxis(f['pressure'][::4], 0, -1)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14a8be94-7c00-4040-aa48-322664c6c43a",
   "metadata": {},
   "source": [
    "## Create copy of data for processing - needs to be done each time noise is added"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "P_JRftuLWcck",
   "metadata": {
    "id": "P_JRftuLWcck"
   },
   "outputs": [],
   "source": [
    "Q = np.copy(Qf)# + np.random.normal(scale=1e-5, loc=0.0, size=Qf.shape)\n",
    "Q[0,0] = -Q[1,1]\n",
    "Q[0,1] = Q[1,0]\n",
    "u = np.copy(uf)\n",
    "P = np.copy(Pf)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80c6c16c-58cb-4fda-b5bb-103faa1aa8f8",
   "metadata": {},
   "source": [
    "## Set parameters for SINDy fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e836d6c-fbcf-4f7a-bcc8-8da5ab57b171",
   "metadata": {
    "id": "1e836d6c-fbcf-4f7a-bcc8-8da5ab57b171"
   },
   "outputs": [],
   "source": [
    "'''All data is arranged as [...,x,y,t], where \"...\" corresponds to vector terms'''\n",
    "lx, ly, lt = Q.shape[-3:]\n",
    "tensorTerm = 0\n",
    "numSamples = 100_000\n",
    "numDataPoints = lx *ly *lt\n",
    "sample = np.arange(numDataPoints)\n",
    "np.random.shuffle(sample)\n",
    "sample = sample[:numSamples]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38d5093a-d062-4656-af35-e62a9024a17f",
   "metadata": {},
   "source": [
    "## Write names of library of terms for SINDy fit (order matters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f82f90d-f4d1-467b-b500-71f39b2a7ee6",
   "metadata": {
    "id": "8f82f90d-f4d1-467b-b500-71f39b2a7ee6"
   },
   "outputs": [],
   "source": [
    "lhs_term = '∇²u'\n",
    "rhs_term_names = []\n",
    "# term_names.append('∇²u')\n",
    "rhs_term_names.append('∂ₜu')\n",
    "rhs_term_names.append('u')\n",
    "rhs_term_names.append('∇.Q')\n",
    "rhs_term_names.append('Q.u')\n",
    "rhs_term_names.append('(u.u)u')\n",
    "rhs_term_names.append('∇(Q:Q)')\n",
    "rhs_term_names.append('∇P')\n",
    "''' This system is incompressible, so I remove the next library term which will always be zero'''\n",
    "# term_names.append('(∇.u)u')\n",
    "\n",
    "rhs_term_names = np.array(rhs_term_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5740af52-3405-48c1-8ef6-a66f1f43c9d4",
   "metadata": {},
   "source": [
    "## Calculate derivatives of data, calculate terms, and sample terms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77442e7e-865b-4dfd-bf3d-1ee7ebbf624c",
   "metadata": {
    "id": "77442e7e-865b-4dfd-bf3d-1ee7ebbf624c"
   },
   "outputs": [],
   "source": [
    "lap_u = calc_gradients(u, lap_order=[1], dh=(dx,dx))\n",
    "grad_Q = calc_gradients(Q, grad_order=[1], dh=(dx,dx))\n",
    "grad_P = calc_gradients(P, grad_order=[1], dh=(dx,dx))\n",
    "dt_u = np.gradient(u, dt, axis=-1)\n",
    "\n",
    "# LHS\n",
    "lhs = np.copy(lap_u)[tensorTerm].flatten()[sample]\n",
    "\n",
    "rhs = []\n",
    "'''∂ₜu term'''\n",
    "tmp = dt_u[tensorTerm].flatten()[sample]\n",
    "rhs.append(tmp)\n",
    "'''u term'''\n",
    "tmp = u[tensorTerm].flatten()[sample]\n",
    "rhs.append(tmp)\n",
    "'''term_names.append('∇.Q')'''\n",
    "tmp = np.einsum('aa...', grad_Q)[tensorTerm].flatten()[sample]\n",
    "rhs.append(tmp)\n",
    "'''Q.u term'''\n",
    "tmp = np.einsum('ia...,a...->i...', Q, u)[tensorTerm].flatten()[sample]\n",
    "rhs.append(tmp)\n",
    "'''(u.u)u term'''\n",
    "tmp = np.einsum('a...,a...->...', u, u)[None,...] *u\n",
    "tmp = tmp[tensorTerm].flatten()[sample]\n",
    "rhs.append(tmp)\n",
    "'''∇(Q:Q) term'''\n",
    "tmp = 2 *np.einsum('iab...,ba...->i...', grad_Q, Q)\n",
    "tmp = tmp[tensorTerm].flatten()[sample]\n",
    "rhs.append(tmp)\n",
    "'''∇P term'''\n",
    "tmp = grad_P[tensorTerm].flatten()[sample]\n",
    "rhs.append(tmp)\n",
    "\n",
    "rhs = np.array(rhs).T"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02f9ca2b-e7f3-4400-967d-629ebc5586bf",
   "metadata": {},
   "source": [
    "## Perform a sequentially thresholded least squares fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf922e56-76f4-4547-bf77-51be7fb7ba2c",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "bf922e56-76f4-4547-bf77-51be7fb7ba2c",
    "outputId": "7825de6c-c75c-48c7-da74-20a1a35fb207"
   },
   "outputs": [],
   "source": [
    "coeff, R2 = sequentially_thresholded_LSQ(rhs, lhs)\n",
    "I = coeff != 0\n",
    "plt.plot(R2, '-o')\n",
    "plt.xlabel('Term number', fontsize=18)\n",
    "plt.ylabel('$R^2$', fontsize=18)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "AnvJTCkZT4lH",
   "metadata": {
    "id": "AnvJTCkZT4lH"
   },
   "outputs": [],
   "source": [
    "fitTerms = 4\n",
    "print('R^2=%0.8f'%R2[fitTerms-1])\n",
    "print(coeff[fitTerms-1][I[fitTerms-1]])\n",
    "print(rhs_term_names[I[fitTerms-1]])"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
